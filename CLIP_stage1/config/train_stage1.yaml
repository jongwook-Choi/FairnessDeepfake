# CLIP Stage1 Training Configuration (v2 - GRL + Adversarial Debiasing)
# FairFace, UTKFace, CausalFace를 활용한 CLIP pre-train weight의 Global bias 제거
#
# 핵심 변경: GRL(Gradient Reversal Layer) 기반 adversarial debiasing
# - Classifier의 gradient가 반전되어 adapter가 인구통계 정보를 제거하는 방향으로 학습
# - Cosine similarity loss로 유용 정보 보존
# - Best model: cosine_sim - 0.3*race_acc - 0.2*gender_acc

# =============================================================================
# Model Configuration
# =============================================================================
model:
  clip_name: "ViT-L/14"              # CLIP 모델 이름
  adapter_hidden_dim: 512            # Adapter hidden 차원
  feature_dim: 768                   # CLIP feature 차원 (ViT-L/14: 768)
  num_races: 4                       # 인종 클래스 수 (Asian, White, Black, Other)
  num_genders: 2                     # 성별 클래스 수 (Male, Female)
  dropout: 0.1                       # Dropout 비율
  normalize_features: true           # Feature normalization 여부
  use_grl: true                      # GRL 사용 여부 (핵심 변경)
  clip_download_root: "/data/cuixinjie/weights"  # CLIP 가중치 경로

# =============================================================================
# GRL Configuration (Gradient Reversal Layer)
# =============================================================================
grl:
  initial_lambda: 0.0                # 초기 GRL lambda (학습 초기엔 adversarial 약하게)
  max_lambda: 1.0                    # 최대 GRL lambda
  gamma: 10.0                        # DANN sigmoid schedule 가파른 정도
  schedule: "dann"                   # scheduling 방식: dann, linear, step

# =============================================================================
# Dataset Configuration
# =============================================================================
dataset:
  # 데이터셋 경로 (Stage1: Global bias 제거용)
  fairface_root: "/workspace/datasets/fairface"
  utkface_root: "/workspace/datasets/UTKFace"
  causalface_root: "/workspace/datasets/CausalFace"
  ffpp_root: "/workspace/datasets/fairness/ff++"

  # Train 데이터셋 (FairFace, UTKFace, CausalFace)
  train_datasets:
    - fairface
    - utkface
    - causalface

  # Validation에 FF++ 사용 여부
  use_ffpp_for_validation: true

  resolution: 224                    # 입력 이미지 해상도
  use_data_augmentation: true        # 데이터 증강 사용 여부
  use_balance_sampling: true         # Subgroup 균형 샘플링 사용 여부
  max_samples_per_subgroup: 0        # 0 = 최소 subgroup 크기 기준, >0 = 지정된 수로 제한

  # CLIP normalization
  mean: [0.48145466, 0.4578275, 0.40821073]
  std: [0.26862954, 0.26130258, 0.27577711]

# =============================================================================
# Loss Configuration
# =============================================================================
loss:
  lambda_race: 1.0                   # Race adversarial loss 가중치 (GRL 반전)
  lambda_gender: 0.5                 # Gender adversarial loss 가중치 (GRL 반전)
  lambda_similarity: 2.0             # Cosine similarity 보존 loss (신규)
  lambda_fairness: 0.5               # Global Sinkhorn fairness loss 가중치
  lambda_pairwise: 0.3               # Pairwise Sinkhorn fairness loss 가중치
  sinkhorn_blur: 0.0001              # Sinkhorn blur 파라미터
  label_smoothing: 0.0               # Label smoothing

# =============================================================================
# Training Configuration
# =============================================================================
training:
  num_epochs: 20                     # 학습 에포크 수 (10 -> 20, GRL scheduling 위해)
  batch_size: 64                     # 배치 크기 (8의 배수 권장)
  num_workers: 4                     # DataLoader worker 수
  use_amp: false                     # Mixed precision 사용 여부

  # Optimizer
  optimizer:
    type: "adamw"                    # optimizer 타입 (adam, adamw, sgd)
    lr: 0.001                        # 학습률
    weight_decay: 0.0001             # Weight decay
    betas: [0.9, 0.999]              # Adam betas

  # Scheduler
  scheduler:
    type: "cosine"                   # scheduler 타입 (cosine, step, none)
    T_max: 20                        # CosineAnnealing T_max (num_epochs에 맞춤)
    eta_min: 0.00001                 # CosineAnnealing 최소 lr

# =============================================================================
# Best Model Selection (v2 - 일관된 기준)
# =============================================================================
# score = w_cosine * cosine_sim + w_race_acc * race_acc + w_gender_acc * gender_acc
# race_acc가 random(25%)에 가까울수록, cosine_sim이 높을수록 좋은 모델
best_model_selection:
  w_cosine: 1.0                      # Cosine similarity 가중치 (높을수록 좋음)
  w_race_acc: -0.3                   # Race accuracy 가중치 (음수: 낮을수록 좋음)
  w_gender_acc: -0.2                 # Gender accuracy 가중치 (음수: 낮을수록 좋음)

# =============================================================================
# Logging Configuration
# =============================================================================
logging:
  log_dir: "/workspace/code/CLIP_stage1/logs"  # 로그 디렉토리
  save_every_epoch: false            # 매 에포크마다 체크포인트 저장
  log_interval: 100                  # 로깅 간격 (iterations)

# =============================================================================
# Device Configuration
# =============================================================================
device: "cuda"                       # 학습 device
seed: 42                             # Random seed
