# Stage 2 Independent Adapter Configuration
# Independent Dual Adapter with Cross-Attention Fusion
#
# 설계 철학:
# - Stage 1 Adapter: CLIP의 Global Bias 보정 (Frozen)
# - Stage 2 Adapter: Detection + Local Fairness (Trainable)
# - Cross-Attention Fusion: Detection이 Fairness를 참조
# - Dynamic Loss Weighting: Uncertainty-based automatic loss balancing

# ==================== Model Configuration ====================
model:
  clip_name: "ViT-L/14"
  feature_dim: 768

  # Stage 1 Adapter (Frozen): Global Fairness 보정
  stage1_hidden_dim: 512

  # Stage 2 Adapter (Trainable): Detection + Local Fairness
  stage2_hidden_dim: 384

  # Cross-Attention Fusion
  fusion_num_heads: 8

  # Binary Classifier
  classifier_hidden_dims: [384, 192]
  num_classes: 2

  # 기타
  dropout: 0.1
  normalize_features: true

# Stage 1 Checkpoint (Additive Adapter 가중치)
stage1_checkpoint: "/workspace/code/CLIP_stage1/logs/stage1_2026-01-20-12-31-57/checkpoint_best.pth"

# ==================== Dataset Configuration ====================
dataset:
  fairness_root: "/workspace/datasets/fairness"
  train_dataset: ["ff++"]
  validation_dataset: ["ff++"]
  test_dataset: ["celebdf", "dfd", "dfdc"]
  resolution: 256
  use_data_augmentation: true

  # Subgroup 균형 샘플링
  use_balance_sampling: false       # Subgroup 내 Real/Fake 균형 (기존)
  use_subgroup_balance: true        # Subgroup 간 균형 (Dataset-level)
  use_subgroup_sampler: true        # Batch-level subgroup 균형
  skip_unknown_attributes: false

# Data normalization (ImageNet default)
mean: [0.485, 0.456, 0.406]
std: [0.229, 0.224, 0.225]

# ==================== Training Configuration ====================
training:
  num_epochs: 30
  train_batch_size: 256 # 64 -> 256 FIX
  val_batch_size: 64
  num_workers: 4

# ==================== Optimizer Configuration ====================
optimizer:
  type: "adamw"
  lr: 0.0001          # 1e-4
  weight_decay: 0.01
  betas: [0.9, 0.999]
  eps: 1.0e-8

# ==================== Scheduler Configuration ====================
scheduler:
  use_scheduler: true
  name: "WarmupCosine"       # Variant1: 안정적인 단조 감소
  T_0: 5              # (CosineAnnealingWarmRestarts용)
  T_mult: 2           # (CosineAnnealingWarmRestarts용)
  eta_min: 1.0e-6     # 최소 learning rate

  # WarmupCosine 옵션
  warmup_epochs: 2    # Variant1: 1 → 2

# ==================== Loss Configuration ====================
loss:
  type: "cross_entropy"    # cross_entropy, focal, bce
  focal_alpha: 0.25
  focal_gamma: 2.0
  label_smoothing: 0.0
  class_weights: null

# Fairness Loss Configuration
fairness_loss:
  sinkhorn_blur: 1.0e-4    # Sinkhorn regularization
  sinkhorn_p: 2            # p-norm
  scaling: 0.9             # Sinkhorn scaling
  min_samples_per_subgroup: 2
  num_subgroups: 8

# Loss Weighting Configuration
loss_weighting:
  type: "fixed"          # "dynamic" (uncertainty-based) or "fixed"
  # Dynamic weighting 옵션
  init_log_var_cls: 0.0    # 초기 log variance for classification
  init_log_var_fair: 0.0   # 초기 log variance for fairness
  # Fixed weighting 옵션 (type이 fixed일 때)
  lambda_cls: 1.0
  lambda_fair: 0.1

# Gradient Clipping
gradient_clip_max_norm: 1.0

# ==================== Logging Configuration ====================
logging:
  log_dir: "/workspace/code/CLIP_stage2/logs"
  experiment_name: "stage2_v1_fixed_warmup"  # Variant1: 실험 구분
  print_freq: 50
  save_freq: 1

# ==================== Evaluation Configuration ====================
evaluation:
  eval_freq: 1
  save_best_only: true
  metric_for_best: "auc"   # auc, acc, eer
  test_every_n_epochs: 5   # N 에포크마다 테스트셋 평가
  test_datasets: ["celebdf", "dfd", "dfdc"]  # 테스트 데이터셋

# ==================== Hardware Configuration ====================
device: "cuda"
seed: 42
deterministic: true

# CLIP weights download path
clip_download_root: "/data/cuixinjie/weights"

# ==================== Expected Trainable Parameters ====================
# Component          | Status    | Parameters
# -------------------|-----------|------------
# CLIP Encoder       | Frozen    | ~303M
# Stage 1 Adapter    | Frozen    | ~1.2M
# Stage 2 Adapter    | Trainable | ~600K
# Cross-Attn Fusion  | Trainable | ~2.4M
# Dynamic Gate       | Trainable | ~1K
# Loss Weighting     | Trainable | 2 params
# Binary Classifier  | Trainable | ~400K
# -------------------|-----------|------------
# Total Trainable    |           | ~3.4M
